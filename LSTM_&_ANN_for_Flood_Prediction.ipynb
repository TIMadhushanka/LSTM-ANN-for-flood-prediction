{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the code used for my research 'Long Short Term Memory and Feedforward Artificial Neural Network for Flood Prediction'. I used three rain gauge data and one river gauge data for this analysis. I created the model so it takes three rainfall and the river water level data for past 15 days to predict the following day water level by sliding window method.\n"
      ],
      "metadata": {
        "id": "mQl-IKRrMKzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Analysis"
      ],
      "metadata": {
        "id": "bKQrBSi8YQz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing useful libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math"
      ],
      "metadata": {
        "id": "rTIHLGCyOmN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount the google drive to access it\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G8I2dj3Q0TKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To upload a file to Colab\n",
        "\n",
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "id": "pu0O6xSMOpjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the excel file containing all the data\n",
        "df=pd.read_excel('Data_84_12.xlsx')\n",
        "df.head()\n",
        "\n",
        "#Columns of the table are 'Date','Rainfall_A','Rainfall_B','Rainfall_C','Water_Level'"
      ],
      "metadata": {
        "id": "iGoyiHdrB2rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJnLI7kcQHPE"
      },
      "outputs": [],
      "source": [
        "#Extracting dates for the graphs\n",
        "\n",
        "dates=df['Date'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVDMoSPmVWn3"
      },
      "outputs": [],
      "source": [
        "#Use the date column as the index\n",
        "\n",
        "df.Date=pd.to_datetime(df.Date)\n",
        "df.set_index('Date',inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the correlation among the rain gauges\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "corrAB, corrBC, corrAC,  = pearsonr(df['Rainfall_A'],df['Rainfall_B'])[0], pearsonr(df['Rainfall_B'],df['Rainfall_C'])[0], pearsonr(df['Rainfall_A'],df['Rainfall_C'])[0]\n",
        "print('Pearsons correlation between A & B: %.3f' % corrAB)\n",
        "print('Pearsons correlation between B & C: %.3f' % corrBC)\n",
        "print('Pearsons correlation between A & C: %.3f' % corrAC)\n",
        "\n",
        "#You can check the correlation between rain and river gauges too"
      ],
      "metadata": {
        "id": "ukVskOMRPoYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the rainfalls\n",
        "\n",
        "plt.figure(figsize=(18,7))\n",
        "plt.plot(df['Rainfall_A'])\n",
        "plt.title('Rainfall_A', fontsize=28)\n",
        "plt.xlabel('Date', fontsize=24)\n",
        "plt.ylabel('Water level in meters', fontsize=24)\n",
        "\n",
        "# Change font sizes for x and y axis tick labels\n",
        "plt.xticks(fontsize=22)\n",
        "plt.yticks(fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lsNCOye3ynwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create boxplots so you can see the annual and monthly variations of the data\n",
        "\n",
        "#Create 'Year' and 'Month' columns based on the date\n",
        "df2=df.copy()\n",
        "df2['Year']=[d.year for d in df2.index]\n",
        "df2['Month']=[d.strftime('%b') for d in df2.index]\n",
        "\n",
        "#Create subplots\n",
        "\n",
        "plt.figure(figsize=(26,22))\n",
        "\n",
        "plt.subplot(321)\n",
        "sns.boxplot(x='Month',y='Rainfall_A',data=df2)\n",
        "plt.xlabel('Month',fontsize=18)\n",
        "plt.ylabel('Rainfall in mm',fontsize=18)\n",
        "plt.title('Monthly Rainfall-A',fontsize=22)\n",
        "plt.xticks(rotation=0, fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.subplot(322)\n",
        "sns.boxplot(x='Month',y='Rainfall_B',data=df2)\n",
        "plt.xlabel('Month',fontsize=18)\n",
        "plt.ylabel('Rainfall in mm',fontsize=18)\n",
        "plt.title('Monthly Rainfall-B',fontsize=22)\n",
        "plt.xticks(rotation=0, fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.subplot(323)\n",
        "sns.boxplot(x='Month',y='Rainfall_C',data=df2)\n",
        "plt.xlabel('Month',fontsize=18)\n",
        "plt.ylabel('Rainfall in mm',fontsize=18)\n",
        "plt.title('Monthly Rainfall-C',fontsize=22)\n",
        "plt.xticks(rotation=0, fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.subplot(324)\n",
        "plt.plot(df['Water_Level'])\n",
        "plt.title('Water level', fontsize=22)\n",
        "plt.xlabel('Date', fontsize=18)\n",
        "plt.ylabel('Water level in meters', fontsize=18)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.subplot(325)\n",
        "sns.boxplot(x='Year',y='Water_Level',data=df2)\n",
        "plt.xlabel('Year',fontsize=18)\n",
        "plt.ylabel('Water level in meters',fontsize=18)\n",
        "plt.title('Annual Water Levels',fontsize=22)\n",
        "plt.xticks(rotation=75, fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "plt.subplot(326)\n",
        "sns.boxplot(x='Month',y='Water_Level',data=df2)\n",
        "plt.xlabel('Month',fontsize=18)\n",
        "plt.ylabel('Water level in meters',fontsize=18)\n",
        "plt.title('Monthly Water Levels',fontsize=22)\n",
        "plt.xticks(rotation=0, fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "#Save the image in the google drive\n",
        "save_path = '/content/drive/MyDrive/box_plots.png'\n",
        "plt.savefig(save_path)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zIsqWp2-y9kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining a sliding window"
      ],
      "metadata": {
        "id": "i57VF_yrw1lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_seq(n_past,n_future,dataset):\n",
        "  #Empty lists to be populated using formatted training data\n",
        "  trainX = []\n",
        "  trainY = []\n",
        "  for i in range(n_past, len(dataset) - n_future +1):\n",
        "    trainX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
        "    trainY.append(dataset[i + n_future - 1:i + n_future, 3])\n",
        "  return np.array(trainX), np.array(trainY)\n",
        "\n"
      ],
      "metadata": {
        "id": "WC7F4s-lw1lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardize the data to reduce the range\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_for_training_scaled = scaler.fit_transform(df)"
      ],
      "metadata": {
        "id": "Zzcs5repw1lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test sets by 7:3\n",
        "\n",
        "train_size=int(len(df)*0.7)\n",
        "test_size=len(df)-train_size\n",
        "\n",
        "train_data=df_for_training_scaled[:train_size,:]\n",
        "test_data=df_for_training_scaled[train_size:,:]"
      ],
      "metadata": {
        "id": "FIEfD4ZMw1lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create inputs and outputs using the sliding window function\n",
        "\n",
        "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
        "n_past = 15  # Number of past days we want to use to predict the future.\n",
        "\n",
        "trainX,trainY=to_seq(n_past,n_future,train_data)\n",
        "testX,testY=to_seq(n_past,n_future,test_data)\n",
        "\n",
        "print('trainX shape == {}.'.format(trainX.shape))\n",
        "print('trainY shape == {}.'.format(trainY.shape))\n",
        "print('\\n')\n",
        "print('testX shape == {}.'.format(testX.shape))\n",
        "print('testY shape == {}.'.format(testY.shape))"
      ],
      "metadata": {
        "id": "idketf0Ow1lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dates for plotting graphs\n",
        "\n",
        "train_dates=dates[:train_size]\n",
        "test_dates=dates[train_size:]\n",
        "\n",
        "train_dates=train_dates[-trainY.shape[0]:]\n",
        "test_dates=test_dates[-testY.shape[0]:]"
      ],
      "metadata": {
        "id": "IOtCOTJOw1la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM model"
      ],
      "metadata": {
        "id": "WxKWJQrb1HKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evuZ_bR-Gw1L"
      },
      "outputs": [],
      "source": [
        "# define model with one hidden layer containing 64 LSTM units\n",
        "# One output node for the next day water level prediction\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1],trainX.shape[2]),return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSGKZzEWGw1L"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "\n",
        "learning_rate=0.001\n",
        "batch_size=32\n",
        "from keras.optimizers import Adam\n",
        "opt=Adam(learning_rate)\n",
        "model.compile(optimizer=opt, loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5rx0cG6Gw1M"
      },
      "source": [
        "##Checkpoints to save the best model and Early stopping as the regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7rF65M-Gw1M"
      },
      "outputs": [],
      "source": [
        "file_path='/content/drive/MyDrive/LSTM/best_model' #The location of the saved model\n",
        "checkpoint=ModelCheckpoint(file_path,monitor='val_loss',save_best_only=True, verbose=1)\n",
        "es=EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HswRbd32Gw1N"
      },
      "outputs": [],
      "source": [
        "# fit model\n",
        "history=model.fit(trainX,trainY,validation_split=0.1,batch_size=batch_size,verbose=2,epochs=200,callbacks=[checkpoint,es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLHhb5cOGw1O"
      },
      "outputs": [],
      "source": [
        "#Check the loss vs epochs during training\n",
        "plt.figure(figsize=(10,15))\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUPF86MtGw1N"
      },
      "outputs": [],
      "source": [
        "#Load the best model\n",
        "\n",
        "from keras.models import load_model\n",
        "model=load_model('/content/drive/MyDrive/LSTM/best_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiCKPPwkGw1N"
      },
      "outputs": [],
      "source": [
        "#Model evaluation\n",
        "\n",
        "train_loss=model.evaluate(trainX,trainY)\n",
        "test_loss=model.evaluate(testX,testY)\n",
        "print('trained model, train_loss: {:5.3f}%'.format(100*train_loss))\n",
        "print('Trained model, test_loss: {:5.3f}%'.format(100*test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To3S4y1LGFDw"
      },
      "outputs": [],
      "source": [
        "#Prediction\n",
        "\n",
        "yhat = model.predict(testX, verbose=0)\n",
        "yhatr = model.predict(trainX, verbose=0)\n",
        "\n",
        "train_predict_LSTM=scaler.inverse_transform(np.repeat(yhatr,4,axis=1))[:,3]\n",
        "test_predict_LSTM=scaler.inverse_transform(np.repeat(yhat,4,axis=1))[:,3]\n",
        "\n",
        "trainY_LSTM=scaler.inverse_transform(np.repeat(trainY,4,axis=1))[:,3]\n",
        "testY_LSTM=scaler.inverse_transform(np.repeat(testY,4,axis=1))[:,3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,7))\n",
        "plt.plot(test_dates,test_predict_LSTM,color='r',label='Predicted')\n",
        "plt.plot(test_dates,testY_LSTM,label='Actual')\n",
        "plt.xlabel('Dates',fontsize=24)\n",
        "plt.ylabel('Water Level',fontsize=24)\n",
        "plt.legend(loc='upper left',fontsize=22)\n",
        "plt.title('Predicted vs Actual Water Levels - LSTM',fontsize=28)\n",
        "\n",
        "plt.xticks(fontsize=22)\n",
        "plt.yticks(fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SwSdIGBhpfmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANN"
      ],
      "metadata": {
        "id": "8c2snC083hsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshaping the data to be compatible with ANN architecture\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1] * trainX.shape[2]))\n",
        "testX = np.reshape(testX, (testX.shape[0], testX.shape[1] * testX.shape[2]))\n",
        "\n",
        "print('trainX shape == {}.'.format(trainX.shape))\n",
        "print('trainY shape == {}.'.format(trainY.shape))\n",
        "print('\\n')\n",
        "print('testX shape == {}.'.format(testX.shape))\n",
        "print('testY shape == {}.'.format(testY.shape))"
      ],
      "metadata": {
        "id": "kPg9Pgpjw1lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model with one hidden layer containing 64 neurons\n",
        "# One output node for the next day water level prediction\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(trainX.shape[1],)))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "w5QYcYBPw1lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "\n",
        "learning_rate=0.001\n",
        "batch_size=32\n",
        "from keras.optimizers import Adam\n",
        "opt=Adam(learning_rate)\n",
        "model.compile(optimizer=opt, loss='mse')"
      ],
      "metadata": {
        "id": "PnEcvOHNw1lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path='/content/drive/MyDrive/ANN/best_model' #The location of the saved model\n",
        "checkpoint=ModelCheckpoint(file_path,monitor='val_loss',save_best_only=True, verbose=1)\n",
        "es=EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=1)"
      ],
      "metadata": {
        "id": "42PxOFarw1lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "history=model.fit(trainX,trainY,validation_split=0.1,batch_size=batch_size,verbose=2,epochs=200,callbacks=[checkpoint,es])"
      ],
      "metadata": {
        "id": "CK6qMWv1w1lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZHPg1llHw1lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model=load_model('/content/drive/MyDrive/ANN/best_model')"
      ],
      "metadata": {
        "id": "txzA-L-ow1lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss=model.evaluate(trainX,trainY)\n",
        "test_loss=model.evaluate(testX,testY)\n",
        "print('trained model, train_loss: {:5.3f}%'.format(100*train_loss))\n",
        "print('Trained model, test_loss: {:5.3f}%'.format(100*test_loss))"
      ],
      "metadata": {
        "id": "j0ZFLescw1ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(testX, verbose=0)\n",
        "yhatr = model.predict(trainX, verbose=0)\n",
        "\n",
        "train_predict_ANN=scaler.inverse_transform(np.repeat(yhatr,4,axis=1))[:,3]\n",
        "test_predict_ANN=scaler.inverse_transform(np.repeat(yhat,4,axis=1))[:,3]\n",
        "\n",
        "trainY_ANN=scaler.inverse_transform(np.repeat(trainY,4,axis=1))[:,3]\n",
        "testY_ANN=scaler.inverse_transform(np.repeat(testY,4,axis=1))[:,3]\n"
      ],
      "metadata": {
        "id": "syBN7vMKw1ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,7))\n",
        "plt.plot(test_dates,test_predict_ANN,color='r',label='Predicted')\n",
        "plt.plot(test_dates,testY_ANN,label='Actual')\n",
        "plt.xlabel('Dates',fontsize=24)\n",
        "plt.ylabel('Water Level',fontsize=24)\n",
        "plt.legend(loc='upper left',fontsize=22)\n",
        "plt.title('Predicted vs Actual Water Levels - LSTM',fontsize=28)\n",
        "\n",
        "plt.xticks(fontsize=22)\n",
        "plt.yticks(fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "78V263Dl54dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RMSE"
      ],
      "metadata": {
        "id": "A8MjIJpF4u-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate root mean squared error\n",
        "import math\n",
        "\n",
        "def RMSE(observed, simulated):\n",
        "  return math.sqrt(mean_squared_error(observed, simulated))\n"
      ],
      "metadata": {
        "id": "sqmgkRVI4t_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nash Sutcliffe"
      ],
      "metadata": {
        "id": "8ToDUk26tRpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_nse(observed, simulated):\n",
        "    if len(observed) != len(simulated):\n",
        "        raise ValueError(\"The lengths of observed and simulated data do not match.\")\n",
        "\n",
        "    mean_observed = sum(observed) / len(observed)\n",
        "\n",
        "    numerator = sum((obs - sim) ** 2 for obs, sim in zip(observed, simulated))\n",
        "    denominator = sum((obs - mean_observed) ** 2 for obs in observed)\n",
        "\n",
        "    nse = 1 - (numerator / denominator)\n",
        "    return nse"
      ],
      "metadata": {
        "id": "8fwQCktgtM0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Root Mean Square Error (RMSE) - ANN:\", RMSE(testY_ANN,test_predict_ANN))\n",
        "print(\"Nash-Sutcliffe Efficiency (NSE) - ANN:\", calculate_nse(testY_ANN,test_predict_ANN))\n",
        "print('\\n')\n",
        "print(\"Root Mean Square Error (RMSE) - LSTM:\", RMSE(testY_LSTM,test_predict_LSTM))\n",
        "print(\"Nash-Sutcliffe Efficiency (NSE) - LSTM:\", calculate_nse(testY_LSTM,test_predict_LSTM))"
      ],
      "metadata": {
        "id": "KCbA9P3j5SSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}